Course Structure:

1. [Introduction](#module1)
2. [Computing Machinery and Intelligence (Turing)](#module2)
3. [Logic](#module3)
4. [Rules](#module4)
5. [Concepts](#module5)
6. [Analogy](#module6)
7. [Images](#module7)
8. [Connectionism](#module8)
9. [Neuroscience](#module9)
10. [Emotions](#module10)
11. [Consciousness](#module11)
12. [Embodiment](#module12)
13. [Dynamical Systems](#module13)
14. [Intentionality](#module14)
15. [Externalism](#module15)
16. [Conclusion](#module16)

----------

Cue:

- <a id="module1"></a>[Lecture 1. Introduction](#1)
    - [Introduction](#1A)
        - [Overview](#1A1)
        - [The Cognitive Paradigm](#1A2)
            - [Intelligence](#1A2a)
            - [Mental Representations and Procedures](#1A2b)
            - [Theory Assessment in Cognitive Science](#1A2c)
            - [Summary](#1A2d)
        - [History of Cognitive Science](#1A3)
            - [Prehistory](#1A3a)
            - [The Cognitive Revolution](#1A3b)
    - [The Syllabus](#1B)
        - [Course Materials](#1B1)
        - [Evaluation](#1B2)
        - [Plagiarism](#1B3)
- <a id="module2"></a>[Lecture 2. Computing Machinery and Intelligence (Turing)](#2)
    - [Computing Machinery and Intelligence (Turing)](#2A)
        - [Introduction](#2A1)
        - [Alan Turing](#2A2)
        - [Computing Machinery and Intelligence](#2A3)
        - [Critique of the New Problem](#2A4)
        - [Digital Computer](#2A5)
        - [Universality of Digital Computers](#2A6)
        - [Contrary Views on the Main Question](#2A7)
        - [Issues Raised by the Turing Test](#2A8)
    - [Review Questions and References](#2B)
- <a id="module3"></a>[Lecture 3. Logic](#3)
    - [Logic](#3A)
        - [Overview](#3A1)
        - [Arguments](#3A2)
        - [Propositional Logic](#3A3)
            - [Propositional Symbolization](#3A3a)
            - [Propositional Arguments](#3A3b)
        - [Predicate Logic](#3A4)
            - [Predicate Symbolization](#3A4a)
            - [Predicate Arguments](#3A4b)
        - [Probabilistic Logic](#3A5)
            - [Probabilistic Symbolization](#3A5a)
            - [Probabilistic Arguments](#3A5b)
    - [Evaluation of Logic](#3B)
        - [Overview](#3B1)
        - [Representational Power](#3B2)
        - [Computational Power](#3B3)
            - [Planning](#3B3a)
            - [Decision](#3B3b)
            - [Explanation](#3B3c)
            - [Learning](#3B3d)
            - [Psychological Plausibility](#3B3e)
            - [Summary](#3B3f)
- <a id="module4"></a>[Lecture 4. Rules](#4)
    - [Rules](#4A)
        - [Overview](#4A1)
        - [History of Rules](#4A2)
        - [Rules-Based Systems](#4A3)
        - [Search](#4A4)
            - [Knowledge Space](#4A4a)
            - [Search Strategies](#4A4b)
            - [Heuristics](#4A4c)
            - [Which Strategy to Use](#4A4d)
    - [Evaluation of Rules](#4B)
        - [Overview](#4B1)
        - [Representational Power](#4B2)
        - [Computational Power](#4B3)
            - [Explanation](#4B3a)
            - [Learning](#4B3b)
            - [Language](#4B3c)
        - [Computational Limitations](#4B4)
        - [Psychological Plausibility](#4B5)
        - [Philosophical Issues](#4B6)
- <a id="module5"></a>[Lecture 5. Concepts](#5)
    - [Concepts](#5A)
        - [Overview](#5A1)
        - [History of Concepts](#5A2)
        - [Theories of Concepts](#5A3)
            - [Definitions](#5A3a)
            - [Prototypes](#5A3b)
            - [Exemplars](#5A3c)
            - [Causal](#5A3d)
        - [Tomato - Fruit or Vegetable?](#5A4)
    - [Evaluation of Concepts](#5B)
        - [Overview](#5B1)
        - [Representational Power](#5B2)
        - [Computational Power](#5B3)
            - [Inheritance](#5B3a)
            - [Matching](#5B3b)
        - [Psychological Plausibility](#5B4)
            - [Planning](#5B4a)
            - [Explanation](#5B4b)
            - [Learning](#5B4c)
- <a id="module6"></a>[Lecture 6. Analogy](#6)
    - [Analogy](#6A)
        - [Overview](#6A1)
        - [Analogy as Induction Generalization](#6A2)
        - [Analogy as Extrapolation](#6A3)
        - [The Multiconstraint Theory](#6A4)
            - [Representation](#6A4a)
            - [Constraints on Coherence](#6A4b)
    - [Evaluation of Analogy](#6B)
        - [Overview](#6B1)
        - [Representational Power](#6B2)
            - [Verbal](#6B2a)
            - [Visual](#6B2b)
            - [Emotional](#6B2c)
        - [Computational Power](#6B3)
            - [Analogy Construction](#6B3a)
            - [Explanation](#6B3b)
            - [Learning](#6B3c)
            - [Metaphor](#6B3d)
        - [Limits of Analogical Reasoning](#6B5)
- <a id="module7"></a>[Lecture 7. Images](#7)
    - [Images](#7A)
        - [Overview](#7A1)
        - [The Imagery Debate](#7A2)
        - [Quasi-Pictorialism](#7A3)
        - [Experimental Evidence for Quasi-Pictorialism](#7A4)
            - [Mental Rotation](#7A4a)
            - [Scanning](#7A4b)
            - [Zooming and Inspection](#7A4c)
            - [Demand Characteristics?](#7A4d)
        - [Neurological Evidence for Quasi-Pictorialism](#7A5)
            - [In Search of the Visual Buffer](#7A5a)
            - [Interference](#7A5b)
    - [Evaluation of Images](#7B)
        - [Overview](#7B1)
        - [Descriptionism](#7B2)
            - [Infinite Regress](#7B2a)
            - [Hedging](#7B2b)
            - [Absent Features](#7B2c)
            - [Imagery in Interpreted](#7B2d)
            - [Computational Equivalence](#7B2e)
        - [Representational Power](#7B3)
            - [Deep](#7B3a)
            - [Spatial](#7B3b)
            - [Visual](#7B3c)
            - [Limitations](#7B3d)
        - [Computational Power](#7B4)
            - [Scientific Discovery](#7B4a)
            - [Technical Innovation](#7B4b)
            - [Analogy](#7B4c)
- <a id="module8"></a>[Lecture 8. Connectionism](#8)
- <a id="module9"></a>[Lecture 9. Neuroscience](#9)
- <a id="module10"></a>[Lecture 10. Emotions](#10)
- <a id="module11"></a>[Lecture 11. Consciousness](#11)
- <a id="module12"></a>[Lecture 12. Embodiment](#12)
- <a id="module13"></a>[Lecture 13. Dynamical Systems](#13)
- <a id="module14"></a>[Lecture 14. Intentionality](#14)
- <a id="module15"></a>[Lecture 15. Externalism](#15)
- <a id="module16"></a>[Lecture 16. Conclusion](#16)

----------

# <a id="1"></a>Lecture 1. Introduction

## <a id="1A"></a>Introduction

### <a id="1A1"></a>Overview

- Cognitive Science (CogSci): Study of mind and intelligence
- Main concerns:
    - Identify resources used
    - Understand how they are deployed
- Classic view (1950s–1980s):
    - Symbolic representations
    - Symbol processing
- Recent challenges:
    - Adequacy of symbol processing
    - Brain studies
    - Consciousness, emotions
- Aims of the course:
    - Examine classic CogSci as an account of human thinking and intelligence
    - Examine challenges to classic CogSci
- For now:
    - The CogSci paradigm
    - History of CogSci

### <a id="1A2"></a>The Cognitive Paradigm

- **Paradigm**: a framework for constructing theories
- Cognitive Scientists disagree on the nature of thinking and intelligence
- **Central Thesis**: Thinking is like computation (in a digital computer)
    - Information is represented (data structures)
    - Calculations are performed
- Note: The thesis is an analogy, not a claim of physical resemblance between brains and PCs
- The thesis is a paradigm (Kuhn) more than a theory; it tells researchers …
    1. What to investigate,
    2. What sorts of theories to test, and
    3. How to test and evaluate them.
- For CogSci:
    1. Investigate intelligent behaviours
    2. Theorize about mental representations and procedures
    3. Test using computational models, experiments, etc.

#### <a id="1A2a"></a>Intelligence

Q: What activities require intelligence?
- Typical answers include `recreational challenges`, `argumentation`, `technological work`
- In classic CogSci: intelligence is any activity in which `knowledge` and `expertise` plays a major role
- Intelligence is **knowledge**-intensive

#### <a id="1A2b"></a>Mental Representations and Procedures

![abc](imgs/1a2b_abc.png)
- Mental representation - statements:
    - Block A is on block B.
    - Block B is on the ground.
    - Block C is on the ground.
    - Block C is right of block B.
- Mental procedures - rules:
    - To have block x on block y, place block x on top of block y.
    - To place block x on top of block y, remove other blocks from on top of y, pick up block x, move it on block y and let go of block x.
- Make a plan to spell "CAB"

#### <a id="1A2c"></a>Theory Assessment in Cognitive Science

- Theory: `model` or `explanation` of how an intelligent activity occurs
    - Claim about mental representations and procedures, e.g., statements and rules
- Model **confirmed** if performance matches human behaviour (disconfirmed otherwise)
    - This approach is referred as **cognitive modeling** - the operation of the computer program models or imitates the course of human thinking
- CogSci is highly interdisciplinary
    - Different disciplines employ different testing methods, e.g., brain scans in neuroscience

#### <a id="1A2d"></a>Summary

- Central thesis: Thinking is like computing
    - CRUM: Computational-Representational Understanding of Mind
- CRUM is a paradigm rather than a theory
    - Intelligence is knowledge-intensive
    - Produced by mental representations and procedures
    - Theories are testable through simulation, experiment, etc.
- Evaluation of CRUM depends on
    - Record of success or failure of CRUM theories
    - Performance relative to other paradigms
    - Prospects for future success

### <a id="1A3"></a>History of Cognitive Science

#### <a id="1A3a"></a>Prehistory

- Basic questions:
    1. What do you know and how do you know it? (**epistemology**)
    2. What kind of thing is a mind? (**metaphysics**)
    3. How does a mind give rise to thinking? (**psychology**)
- Some responses:
    - Plato (ca. 400 BC): grasp of ideas, hydraulic analogy
    - Locke (ca. 1700): possession of stattements, blank paper analogy
    - Watson (ca. 1920): S-R arcs, switchboard anaology
    - Weiner (ca. 1940): control configurations, rangefinder analogy

#### <a id="1A3b"></a>The Cognitive Revolution

- 1940s: Turing, electromechanical computers, computer analogy
- 1950s:
    - Miller: short term memory (7&plusmn;2 chunks)
    - Newell & Simon: General Problem Solver
    - Chomsky: syntax as mental representation
- Some general historical trends:
    1. Thinking and intelligence have often been associated with information processing
    2. Information processing technology has often been used as a source of inspiration for theories of cognition

## <a id="1B"></a>The Syllabus

### <a id="1B1"></a>Course Materials

- Textbook
- Reading Materials

### <a id="1B2"></a>Evaluation

- Refer to "Grade Breakdown"
- Discussion in forum is strongly recommended, but not weighted in grade

### <a id="1B3"></a>Plagiarism

...

---------

# <a id="2A"></a>Computing Machinery and Intelligence (Turing)

## <a id="2A1"></a>Introduction CRUM

- CRUM
    - Central thesis: thinking is like computing
    - Expertise and knowledge central to intelligence
- _Computing machinery and intelligence_ (Turing 1950)
    - Can machines think? (1953)
    - Drew attention to the topic
    - Laid out the classic paradigm

## <a id="2A2"></a>Alan Turing

![abc](imgs/2a2_1954_turing_small.jpg)
- Cambridge (1936), Princeton (1938)
- Developed general theory of computation
- Instrumental in breaking the Enigma code (WWII)
- Noted that computers can do intelligent work
- Committed suicide in 1954

## <a id="2A3"></a>Computing Machinery and Intelligence

- The **imitation game**: Why not just use a dictionary definition?
- Subject to **prejudice**:
    - "The question of whether a computer can think is no more interesting than the question of whether a submarine can swim." (Dijkstra)
- Had history been different, our definitions would be different
- Imitation Game
    1. Imitate someone of the opposite gender:
        - (a) man, (b) woman, (c) interrogator
        - Goal: for (c) to distinguish (a) and (b)
        - Teletype interface prevents superficial information from being used by (c)
    2. A computer might imitate a human:
        - (a) computer, (b) person, (c) interrogator
        - Goal: for (c) to distinguish (a) and (b)
        - Teletype interface ensures that only some profound difference, e.g., intelligence, matters

## <a id="2A4"></a>Critique of the New Problem

- To suppose that a (human) brain is required for intelligence is to **beg the question**
- Why is conversing a good test of intelligence?
    - It provides the computer an opportunity to avoid prejudice, superficial judgement
    - We often judge a person's intelligence through conversation
    - We would still need to avoid jumping to conclusions though

## <a id="2A5"></a>Digital Computer

- Among machines, the digital computer holds most interest
- Components of a typical digital computer:
    1. Memory (RAM)
    2. Executive unit (CPU)
    3. Control (program)
- A program is a series of numbers interpreted as instructions by the executive
    - "If position 4505 contains 0 obey next the instruction stored in 6707, otherwise continue straight on"
- Carrying out instructions determines the computer's behaviour

## <a id="2A6"></a>Universality of Digital Computers

- Two kinds of digital computers:
    1. Special purpose (e.g., a chess computer)
    2. General purpose (e.g., a PC)
- A general purpose computer can imitate the activity of any other computer
- If a general purpose computer succeeds at the imitation game, it would be due to its program, not its physical hardware
- Intelligence is highly abstract in nature

## <a id="2A7"></a>Contrary Views on the Main Question

- Original prediction: success in 50 years
    - Later, 100 years
- Current activity: Loebner prize
    - Success is not yet in sight
- Is success out of the question?
- Objections include:  Theological, mathematical, consciousness, originality, etc.
    - Theological objection:
        - Argument: thinking requires a soul, computers have no souls, so computers cannot think
        - Reply: it only follows that computers do not think
            - Being omnipotent, God could give souls to computers, enabling them to think
        - Ultimately, whether computers can think is an empirical matter, determined by empirical tests (e.g., the imitation game)
            - Biblical arguments about empirical matters is unreliable
    - Mathematical objection:
        - Some questions are answerable by humans and not by digital computers:
            - G&ouml;del's theorem shows that there are questions of logic not answerable, in principle, by a given computer
            - The person framing the question can determine the answer
        - Reply: there may be such questions for any given human
            - Perhaps a computer could scan your brain and frame a question unanswerable by you, in principle
            - The computer could computer the answer though
        - The G&ouml;del argument **begs the question**
    - Consciousness objection:
        - We can know that something thinks only if we know that it has conscious experiences
            - It is like something to be intelligent
        - Reply: We know of our own conscious experiences only
            - Solipsism: only I am known to be conscious
        - To avoid absurdity, we must admit behavioural evidence for intelligence
            - E.g., the imitation game
    - Originality objection:
        - Lady Lovelace noted that Babbage's Analytical engine had no pretense to originality
            - Perhaps it lacked enough capacity
        - A digital computer simply obeys its instructions and so does nothing original, unlike intelligent humans
        - Reply:
            1. The objection begs the question: Perhaps the same is true of humans
            2. "Machines take me by surprise with great frequency". But they are predictable in principle? See point 1.

## <a id="2A8"></a>Issues Raised by the Turing Test

- Turing deemphasizes physical constitution and emphasizes possession of knowledge
    - Is hardware truly beside the point?
    - Perhaps intelligence requires a brain
- The imitation game is indifferent to experience and learning
    - Could a "brain in a vat" be intelligent?
    - Perhaps intelligence requires a body

# <a id="2B"></a>Review Questions and References

----------

# <a id="3"></a>Lecture 3. Logic


## <a id="#3A"></a>Logic


### <a id="#3A1"></a>Overview

- **Logic**: study of arguments
    - 

### <a id="#3A2"></a>Arguments


### <a id="#3A3"></a>Propositional Logic


#### <a id="#3A3a"></a>Propositional Symbolization


#### <a id="#3A3b"></a>Propositional Arguments


### <a id="#3A4"></a>Predicate Logic


#### <a id="#3A4a"></a>Predicate Symbolization


#### <a id="#3A4b"></a>Predicate Arguments


### <a id="#3A5"></a>Probabilistic Logic


#### <a id="#3A5a"></a>Probabilistic Symbolization


#### <a id="#3A5b"></a>Probabilistic Arguments


## <a id="#3B"></a>Evaluation of Logic


### <a id="#3B1"></a>Overview


### <a id="#3B2"></a>Representational Power


### <a id="#3B3"></a>Computational Power


#### <a id="#3B3a"></a>Planning


#### <a id="#3B3b"></a>Decision


#### <a id="#3B3c"></a>Explanation


#### <a id="#3B3d"></a>Learning


#### <a id="#3B3e"></a>Psychological Plausibility


#### <a id="#3B3f"></a>Summary


----------



# <a id="#4"></a>Lecture 4. Rules


## <a id="#4A"></a>Rules


### <a id="#4A1"></a>Overview


### <a id="#4A2"></a>History of Rules


### <a id="#4A3"></a>Rules-Based Systems


### <a id="#4A4"></a>Search


#### <a id="#4A4a"></a>Knowledge Space


#### <a id="#4A4b"></a>Search Strategies


#### <a id="#4A4c"></a>Heuristics


#### <a id="#4A4d"></a>Which Strategy to Use


## <a id="#4B"></a>Evaluation of Rules


### <a id="#4B1"></a>Overview


### <a id="#4B2"></a>Representational Power


### <a id="#4B3"></a>Computational Power


#### <a id="#4B3a"></a>Explanation


#### <a id="#4B3b"></a>Learning


#### <a id="#4B3c"></a>Language


### <a id="#4B4"></a>Computational Limitations


### <a id="#4B5"></a>Psychological Plausibility


### <a id="#4B6"></a>Philosophical Issues


----------

# <a id="#5"></a>Lecture 5. Concepts


## <a id="#5A"></a>Concepts


### <a id="#5A1"></a>Overview


### <a id="#5A2"></a>History of Concepts


### <a id="#5A3"></a>Theories of Concepts


#### <a id="#5A3a"></a>Definitions


#### <a id="#5A3b"></a>Prototypes


#### <a id="#5A3c"></a>Exemplars


#### <a id="#5A3d"></a>Causal


### <a id="#5A4"></a>Tomato - Fruit or Vegetable?


## <a id="#5B"></a>Evaluation of Concepts


### <a id="#5B1"></a>Overview


### <a id="#5B2"></a>Representational Power


### <a id="#5B3"></a>Computational Power


#### <a id="#5B3a"></a>Inheritance


#### <a id="#5B3b"></a>Matching


### <a id="#5B4"></a>Psychological Plausibility


#### <a id="#5B4a"></a>Planning


#### <a id="#5B4b"></a>Explanation


#### <a id="#5B4c"></a>Learning


----------

# <a id="#6"></a>Lecture 6. Analogy


## <a id="#6A"></a>Analogy


### <a id="#6A1"></a>Overview


### <a id="#6A2"></a>Analogy as Induction Generalization


### <a id="#6A3"></a>Analogy as Extrapolation


### <a id="#6A4"></a>The Multiconstraint Theory


#### <a id="#6A4a"></a>Representation


#### <a id="#6A4b"></a>Constraints on Coherence


## <a id="#6B"></a>Evaluation of Analogy


### <a id="#6B1"></a>Overview


### <a id="#6B2"></a>Representational Power


#### <a id="#6B2a"></a>Verbal


#### <a id="#6B2b"></a>Visual


#### <a id="#6B2c"></a>Emotional


### <a id="#6B3"></a>Computational Power


#### <a id="#6B3a"></a>Analogy Construction


#### <a id="#6B3b"></a>Explanation


#### <a id="#6B3c"></a>Learning


#### <a id="#6B3d"></a>Metaphor


### <a id="#6B5"></a>Limits of Analogical Reasoning


----------

# <a id="#7"></a>Lecture 7. Images


## <a id="#7A"></a>Images


### <a id="#7A1"></a>Overview


### <a id="#7A2"></a>The Imagery Debate


### <a id="#7A3"></a>Quasi-Pictorialism


### <a id="#7A4"></a>Experimental Evidence for Quasi-Pictorialism


#### <a id="#7A4a"></a>Mental Rotation


#### <a id="#7A4b"></a>Scanning


#### <a id="#7A4c"></a>Zooming and Inspection


#### <a id="#7A4d"></a>Demand Characteristics?


### <a id="#7A5"></a>Neurological Evidence for Quasi-Pictorialism


#### <a id="#7A5a"></a>In Search of the Visual Buffer


#### <a id="#7A5b"></a>Interference


## <a id="#7B"></a>Evaluation of Images


### <a id="#7B1"></a>Overview


### <a id="#7B2"></a>Descriptionism


#### <a id="#7B2a"></a>Infinite Regress


#### <a id="#7B2b"></a>Hedging


#### <a id="#7B2c"></a>Absent Features


#### <a id="#7B2d"></a>Imagery in Interpreted


#### <a id="#7B2e"></a>Computational Equivalence


### <a id="#7B3"></a>Representational Power


#### <a id="#7B3a"></a>Deep


#### <a id="#7B3b"></a>Spatial


#### <a id="#7B3c"></a>Visual


#### <a id="#7B3d"></a>Limitations


### <a id="#7B4"></a>Computational Power


#### <a id="#7B4a"></a>Scientific Discovery


#### <a id="#7B4b"></a>Technical Innovation


#### <a id="#7B4c"></a>Analogy


----------
