Course Structure:

1. [Introduction](#module1)
2. [Computing Machinery and Intelligence (Turing)](#module2)
3. [Logic](#module3)
4. [Rules](#module4)
5. [Concepts](#module5)
6. [Analogy](#module6)
7. [Images](#module7)
8. [Connectionism](#module8)
9. [Neuroscience](#module9)
10. [Emotions](#module10)
11. [Consciousness](#module11)
12. [Embodiment](#module12)
13. [Dynamical Systems](#module13)
14. [Intentionality](#module14)
15. [Externalism](#module15)
16. [Conclusion](#module16)

----------

Cue:

- <a id="module1"></a>[Lecture 1. Introduction](#1)
    - [Introduction](#1A)
        - [Overview](#1A1)
        - [The Cognitive Paradigm](#1A2)
            - [Intelligence](#1A2a)
            - [Mental Representations and Procedures](#1A2b)
            - [Theory Assessment in Cognitive Science](#1A2c)
            - [Summary](#1A2d)
        - [History of Cognitive Science](#1A3)
            - [Prehistory](#1A3a)
            - [The Cognitive Revolution](#1A3b)
    - [The Syllabus](#1B)
        - [Course Materials](#1B1)
        - [Evaluation](#1B2)
        - [Plagiarism](#1B3)
- <a id="module2"></a>[Lecture 2. Computing Machinery and Intelligence (Turing)](#2)
    - [Computing Machinery and Intelligence (Turing)](#2A)
        - [Introduction](#2A1)
        - [Alan Turing](#2A2)
        - [Computing Machinery and Intelligence](#2A3)
        - [Critique of the New Problem](#2A4)
        - [Digital Computer](#2A5)
        - [Universality of Digital Computers](#2A6)
        - [Contrary Views on the Main Question](#2A7)
        - [Issues Raised by the Turing Test](#2A8)
    - [Review Questions and References](#2B)
- <a id="module3"></a>[Lecture 3. Logic](#3)
    - [Logic](#3A)
        - [Overview](#3A1)
        - [Arguments](#3A2)
        - [Propositional Logic](#3A3)
            - [Propositional Symbolization](#3A3a)
            - [Propositional Arguments](#3A3b)
        - [Predicate Logic](#3A4)
            - [Predicate Symbolization](#3A4a)
            - [Predicate Arguments](#3A4b)
        - [Probabilistic Logic](#3A5)
            - [Probabilistic Symbolization](#3A5a)
            - [Probabilistic Arguments](#3A5b)
    - [Evaluation of Logic](#3B)
        - [Overview](#3B1)
        - [Representational Power](#3B2)
        - [Computational Power](#3B3)
            - [Planning](#3B3a)
            - [Decision](#3B3b)
            - [Explanation](#3B3c)
            - [Learning](#3B3d)
            - [Psychological Plausibility](#3B3e)
            - [Summary](#3B3f)
- <a id="module4"></a>[Lecture 4. Rules](#4)
    - [Rules](#4A)
        - [Overview](#4A1)
        - [History of Rules](#4A2)
        - [Rules-Based Systems](#4A3)
        - [Search](#4A4)
            - [Knowledge Space](#4A4a)
            - [Search Strategies](#4A4b)
            - [Heuristics](#4A4c)
            - [Which Strategy to Use](#4A4d)
    - [Evaluation of Rules](#4B)
        - [Overview](#4B1)
        - [Representational Power](#4B2)
        - [Computational Power](#4B3)
            - [Explanation](#4B3a)
            - [Learning](#4B3b)
            - [Language](#4B3c)
        - [Computational Limitations](#4B4)
        - [Psychological Plausibility](#4B5)
        - [Philosophical Issues](#4B6)
- <a id="module5"></a>[Lecture 5. Concepts](#5)
    - [Concepts](#5A)
        - [Overview](#5A1)
        - [History of Concepts](#5A2)
        - [Theories of Concepts](#5A3)
            - [Definitions](#5A3a)
            - [Prototypes](#5A3b)
            - [Exemplars](#5A3c)
            - [Causal](#5A3d)
        - [Tomato - Fruit or Vegetable?](#5A4)
    - [Evaluation of Concepts](#5B)
        - [Overview](#5B1)
        - [Representational Power](#5B2)
        - [Computational Power](#5B3)
            - [Inheritance](#5B3a)
            - [Matching](#5B3b)
        - [Psychological Plausibility](#5B4)
            - [Planning](#5B4a)
            - [Explanation](#5B4b)
            - [Learning](#5B4c)
- <a id="module6"></a>[Lecture 6. Analogy](#6)
    - [Analogy](#6A)
        - [Overview](#6A1)
        - [Analogy as Induction Generalization](#6A2)
        - [Analogy as Extrapolation](#6A3)
        - [The Multiconstraint Theory](#6A4)
            - [Representation](#6A4a)
            - [Constraints on Coherence](#6A4b)
    - [Evaluation of Analogy](#6B)
        - [Overview](#6B1)
        - [Representational Power](#6B2)
            - [Verbal](#6B2a)
            - [Visual](#6B2b)
            - [Emotional](#6B2c)
        - [Computational Power](#6B3)
            - [Analogy Construction](#6B3a)
            - [Explanation](#6B3b)
            - [Learning](#6B3c)
            - [Metaphor](#6B3d)
        - [Limits of Analogical Reasoning](#6B5)
- <a id="module7"></a>[Lecture 7. Images](#7)
    - [Images](#7A)
        - [Overview](#7A1)
        - [The Imagery Debate](#7A2)
        - [Quasi-Pictorialism](#7A3)
        - [Experimental Evidence for Quasi-Pictorialism](#7A4)
            - [Mental Rotation](#7A4a)
            - [Scanning](#7A4b)
            - [Zooming and Inspection](#7A4c)
            - [Demand Characteristics?](#7A4d)
        - [Neurological Evidence for Quasi-Pictorialism](#7A5)
            - [In Search of the Visual Buffer](#7A5a)
            - [Interference](#7A5b)
    - [Evaluation of Images](#7B)
        - [Overview](#7B1)
        - [Descriptionism](#7B2)
            - [Infinite Regress](#7B2a)
            - [Hedging](#7B2b)
            - [Absent Features](#7B2c)
            - [Imagery in Interpreted](#7B2d)
            - [Computational Equivalence](#7B2e)
        - [Representational Power](#7B3)
            - [Deep](#7B3a)
            - [Spatial](#7B3b)
            - [Visual](#7B3c)
            - [Limitations](#7B3d)
        - [Computational Power](#7B4)
            - [Scientific Discovery](#7B4a)
            - [Technical Innovation](#7B4b)
            - [Analogy](#7B4c)
- <a id="module8"></a>[Lecture 8. Connectionism](#8)
- <a id="module9"></a>[Lecture 9. Neuroscience](#9)
- <a id="module10"></a>[Lecture 10. Emotions](#10)
- <a id="module11"></a>[Lecture 11. Consciousness](#11)
- <a id="module12"></a>[Lecture 12. Embodiment](#12)
- <a id="module13"></a>[Lecture 13. Dynamical Systems](#13)
- <a id="module14"></a>[Lecture 14. Intentionality](#14)
- <a id="module15"></a>[Lecture 15. Externalism](#15)
- <a id="module16"></a>[Lecture 16. Conclusion](#16)

----------

# <a id="1"></a>Lecture 1. Introduction

## <a id="1A"></a>Introduction

### <a id="1A1"></a>Overview

- Cognitive Science (CogSci): Study of mind and intelligence
- Main concerns:
    - Identify resources used
    - Understand how they are deployed
- Classic view (1950s–1980s):
    - Symbolic representations
    - Symbol processing
- Recent challenges:
    - Adequacy of symbol processing
    - Brain studies
    - Consciousness, emotions
- Aims of the course:
    - Examine classic CogSci as an account of human thinking and intelligence
    - Examine challenges to classic CogSci
- For now:
    - The CogSci paradigm
    - History of CogSci

### <a id="1A2"></a>The Cognitive Paradigm

- **Paradigm**: a framework for constructing theories
- Cognitive Scientists disagree on the nature of thinking and intelligence
- **Central Thesis**: Thinking is like computation (in a digital computer)
    - Information is represented (data structures)
    - Calculations are performed
- Note: The thesis is an analogy, not a claim of physical resemblance between brains and PCs
- The thesis is a paradigm (Kuhn) more than a theory; it tells researchers …
    1. What to investigate,
    2. What sorts of theories to test, and
    3. How to test and evaluate them.
- For CogSci:
    1. Investigate intelligent behaviours
    2. Theorize about mental representations and procedures
    3. Test using computational models, experiments, etc.

#### <a id="1A2a"></a>Intelligence

Q: What activities require intelligence?
- Typical answers include `recreational challenges`, `argumentation`, `technological work`
- In classic CogSci: intelligence is any activity in which `knowledge` and `expertise` plays a major role
- Intelligence is **knowledge**-intensive

#### <a id="1A2b"></a>Mental Representations and Procedures

![abc](imgs/1a2b_abc.png)
- Mental representation - statements:
    - Block A is on block B.
    - Block B is on the ground.
    - Block C is on the ground.
    - Block C is right of block B.
- Mental procedures - rules:
    - To have block x on block y, place block x on top of block y.
    - To place block x on top of block y, remove other blocks from on top of y, pick up block x, move it on block y and let go of block x.
- Make a plan to spell "CAB"

#### <a id="1A2c"></a>Theory Assessment in Cognitive Science

- Theory: `model` or `explanation` of how an intelligent activity occurs
    - Claim about mental representations and procedures, e.g., statements and rules
- Model **confirmed** if performance matches human behaviour (disconfirmed otherwise)
    - This approach is referred as **cognitive modeling** - the operation of the computer program models or imitates the course of human thinking
- CogSci is highly interdisciplinary
    - Different disciplines employ different testing methods, e.g., brain scans in neuroscience

#### <a id="1A2d"></a>Summary

- Central thesis: Thinking is like computing
    - CRUM: Computational-Representational Understanding of Mind
- CRUM is a paradigm rather than a theory
    - Intelligence is knowledge-intensive
    - Produced by mental representations and procedures
    - Theories are testable through simulation, experiment, etc.
- Evaluation of CRUM depends on
    - Record of success or failure of CRUM theories
    - Performance relative to other paradigms
    - Prospects for future success

### <a id="1A3"></a>History of Cognitive Science

#### <a id="1A3a"></a>Prehistory

- Basic questions:
    1. What do you know and how do you know it? (**epistemology**)
    2. What kind of thing is a mind? (**metaphysics**)
    3. How does a mind give rise to thinking? (**psychology**)
- Some responses:
    - Plato (ca. 400 BC): grasp of ideas, hydraulic analogy
    - Locke (ca. 1700): possession of stattements, blank paper analogy
    - Watson (ca. 1920): S-R arcs, switchboard anaology
    - Weiner (ca. 1940): control configurations, rangefinder analogy

#### <a id="1A3b"></a>The Cognitive Revolution

- 1940s: Turing, electromechanical computers, computer analogy
- 1950s:
    - Miller: short term memory (7&plusmn;2 chunks)
    - Newell & Simon: General Problem Solver
    - Chomsky: syntax as mental representation
- Some general historical trends:
    1. Thinking and intelligence have often been associated with information processing
    2. Information processing technology has often been used as a source of inspiration for theories of cognition

## <a id="1B"></a>The Syllabus

### <a id="1B1"></a>Course Materials

- Textbook
- Reading Materials

### <a id="1B2"></a>Evaluation

- Refer to "Grade Breakdown"
- Discussion in forum is strongly recommended, but not weighted in grade

### <a id="1B3"></a>Plagiarism

...

---------

# <a id="2A"></a>Computing Machinery and Intelligence (Turing)

## <a id="2A1"></a>Introduction CRUM

- CRUM
    - Central thesis: thinking is like computing
    - Expertise and knowledge central to intelligence
- _Computing machinery and intelligence_ (Turing 1950)
    - Can machines think? (1953)
    - Drew attention to the topic
    - Laid out the classic paradigm

## <a id="2A2"></a>Alan Turing

![abc](imgs/2a2_1954_turing_small.jpg)
- Cambridge (1936), Princeton (1938)
- Developed general theory of computation
- Instrumental in breaking the Enigma code (WWII)
- Noted that computers can do intelligent work
- Committed suicide in 1954

## <a id="2A3"></a>Computing Machinery and Intelligence

- The **imitation game**: Why not just use a dictionary definition?
- Subject to **prejudice**:
    - "The question of whether a computer can think is no more interesting than the question of whether a submarine can swim." (Dijkstra)
- Had history been different, our definitions would be different
- Imitation Game
    1. Imitate someone of the opposite gender:
        - (a) man, (b) woman, (c) interrogator
        - Goal: for (c) to distinguish (a) and (b)
        - Teletype interface prevents superficial information from being used by (c)
    2. A computer might imitate a human:
        - (a) computer, (b) person, (c) interrogator
        - Goal: for (c) to distinguish (a) and (b)
        - Teletype interface ensures that only some profound difference, e.g., intelligence, matters

## <a id="2A4"></a>Critique of the New Problem

- To suppose that a (human) brain is required for intelligence is to **beg the question**
- Why is conversing a good test of intelligence?
    - It provides the computer an opportunity to avoid prejudice, superficial judgement
    - We often judge a person's intelligence through conversation
    - We would still need to avoid jumping to conclusions though

## <a id="2A5"></a>Digital Computer

- Among machines, the digital computer holds most interest
- Components of a typical digital computer:
    1. Memory (RAM)
    2. Executive unit (CPU)
    3. Control (program)
- A program is a series of numbers interpreted as instructions by the executive
    - "If position 4505 contains 0 obey next the instruction stored in 6707, otherwise continue straight on"
- Carrying out instructions determines the computer's behaviour

## <a id="2A6"></a>Universality of Digital Computers

- Two kinds of digital computers:
    1. Special purpose (e.g., a chess computer)
    2. General purpose (e.g., a PC)
- A general purpose computer can imitate the activity of any other computer
- If a general purpose computer succeeds at the imitation game, it would be due to its program, not its physical hardware
- Intelligence is highly abstract in nature

## <a id="2A7"></a>Contrary Views on the Main Question

- Original prediction: success in 50 years
    - Later, 100 years
- Current activity: Loebner prize
    - Success is not yet in sight
- Is success out of the question?
- Objections include:  Theological, mathematical, consciousness, originality, etc.
    - Theological objection:
        - Argument: thinking requires a soul, computers have no souls, so computers cannot think
        - Reply: it only follows that computers do not think
            - Being omnipotent, God could give souls to computers, enabling them to think
        - Ultimately, whether computers can think is an empirical matter, determined by empirical tests (e.g., the imitation game)
            - Biblical arguments about empirical matters is unreliable
    - Mathematical objection:
        - Some questions are answerable by humans and not by digital computers:
            - G&ouml;del's theorem shows that there are questions of logic not answerable, in principle, by a given computer
            - The person framing the question can determine the answer
        - Reply: there may be such questions for any given human
            - Perhaps a computer could scan your brain and frame a question unanswerable by you, in principle
            - The computer could computer the answer though
        - The G&ouml;del argument **begs the question**
    - Consciousness objection:
        - We can know that something thinks only if we know that it has conscious experiences
            - It is like something to be intelligent
        - Reply: We know of our own conscious experiences only
            - Solipsism: only I am known to be conscious
        - To avoid absurdity, we must admit behavioural evidence for intelligence
            - E.g., the imitation game
    - Originality objection:
        - Lady Lovelace noted that Babbage's Analytical engine had no pretense to originality
            - Perhaps it lacked enough capacity
        - A digital computer simply obeys its instructions and so does nothing original, unlike intelligent humans
        - Reply:
            1. The objection begs the question: Perhaps the same is true of humans
            2. "Machines take me by surprise with great frequency". But they are predictable in principle? See point 1.

## <a id="2A8"></a>Issues Raised by the Turing Test

- Turing deemphasizes physical constitution and emphasizes possession of knowledge
    - Is hardware truly beside the point?
    - Perhaps intelligence requires a brain
- The imitation game is indifferent to experience and learning
    - Could a "brain in a vat" be intelligent?
    - Perhaps intelligence requires a body

# <a id="2B"></a>Review Questions and References

----------

# <a id="3"></a>Lecture 3. Logic


## <a id="#3A"></a>Logic


### <a id="#3A1"></a>Overview

- **Logic**: the study of arguments 
    - Assess their strength 
    - Represent their content and form 
- Example: Does the Bear Patrol work? 
    - Homer: Not a bear in sight. The Bear Patrol must be working like a charm. 
    - Lisa: That's specious reasoning, Dad. 
    - Homer: Thank you, dear. 
    - Lisa: By your logic I could claim that this rock keeps tigers away. 
- What problems are there with Homer's argument? 
- The strength of the argument rests on its form and the reasons given 
- Introduction to modern symbolic logic
    - Propositional logic 
    - Predicate logic 
    - Probability 
- Is formal logic a model for mental representations and procedures? 

### <a id="#3A2"></a>Arguments

- Aristotle (385-322 BC) found that form affects argument assessment 
    - **formal** logic 
- Homer's argument: 
<table class="tg">
    <tr>
        <td>[There is a gear Patron]</td>
    </tr>
    <tr>
        <td>Not a bear in sight</td>
    </tr>
    <tr>
        <td> ---------- </td>
    </tr>
    <tr>
        <td>Therefore, the Boar Patrol keeps bears away</td>
    </tr>
</table>
Premises, underline, conclusion 
Argument validity 
Syl ogism: 2 premises 
All geese are birds. 
All birds have Wings. 
All geese have Wings. 
This argument is valid. If the premises are true, 
then the conclusion is true also 
All lions are Catg. 
All Catg hava fur. 
All lions have 
All lions are 
All waffles are biræ. 
All lions are biræ. 
Validity (cont.) 
Not all argument forms are valid: 
There is a Bear Patrol 
Not a bear in sight 
The Bear patrol keeps bears away 
Likewise: 
There is an anti-tiger rock. 
Not a tiqer in siqht, 
The anti-tiger rock keeps tigers away. 
Any argument Of this form is non-valid 

### <a id="#3A3"></a>Propositional Logic

Propositional logic 
Problem: not a I valid arguments are syllogisms 
Boole (1815—1864): Treat logic like algebra 
If Scu:rates is a man, then he is mortal. 
ig a man. 
Socrates is mortal. 
Becomes 
(S -Socrates a man-I 
The first premise is a pair of sentences (S, M) 
connected by 

#### <a id="#3A3a"></a>Propositional Symbolization

Propositional symbolization 
Simple sentences are s'ngle letters, e.g., 
"Jill likes movies" (Ml, and 
"Jill likes starry skies" (S) 
Complex sentences are single letters combined 
by connectives, e.g., 
1. Conjunction: "Jill likes movies and starry skies" 
1M & Sl 
Disjunction: -Jill ikes movies or starry skies" (M v S). 
Implication: "If Jill likes movies, then Jill likes starry 
skies" (M Sl 
Negation: "Jill does not like movies" I-MI. 
Propositional (cont.) 
The rent is due and I have no money. 
London and Paris are national capitals. 
Tme is not on my side. 
The campers were tired, but they were happy 
I will go hiking if I finish my work first. 
If nominated I will not run, and if elected I will not 
serve. 
Exercise 
Symbolize the following using the 
symbols given 
, A conjunction has two components while a 
negation has only one. CC, NI 
2 If we attempt this pay then we'l either win 
big or lose big. IA, W, L) 
1 will leave town unless you call me. (L, Cl 
Skip class again and you won't pass the 
course. (S, P) 

#### <a id="#3A3b"></a>Propositional Arguments

Propositional arguments 
Symbolization exposes form and validity: 
If the gear Patrol w ONS , be arg are in Sight. W g 
patrol 
NO bears in Sight. 
An argument Of this form is called modus 
ponens and is always valid: 
Propositional arguments 
(cont.) 
Not every form Of argument is valid, e.g., 
If the Bear Pat wo 'KS, then no bears are in Sight. W g 
No are in 
The Bear Patrol works. 
This form is a fallacy: affirming the 
consequent. It is always non-valid: 

### <a id="#3A4"></a>Predicate Logic

Predicate logic 
Many arguments valid in English are not 
valid in propositional logic, e.g., 
A geese are birds. 
All birds have winqs. 
A geese have Wings. 
Propositional logic does not symbo ize 
content shared among statements 
Pred cate logic addresses this deficiency 

#### <a id="#3A4a"></a>Predicate Symbolization

Predicate symbolization 
Sentences are broken down into predicates and 
terms, e.g., 
"Bill has a great smile." 
"Jill is witty and intelligent." 
"Tina is taller than Jill." 
Becomes 
Jill) 
(Sx: x has a great smile; b Billl 
IWx: x is witty: Ix: x is intelligent; j 
ITxy: x is taller than y; t — Tlnal 
Quantifiers 
wj&lj 
Quantifiers symbolize English quantity adverbs: 
The universal quantifier The sentence applies to 
every individual 
The existential quantifier The sentence applies to 
at least some individua . 
For example: 
"Some peog.e just do not listen." 
"All is well that ends well. 
likes a smartass." 
8 Lxy)) 
Exercise 
Symbolize the following using the 
symbols given 
Some people can't be bought (P, B). 
A penny saved is a penny earned (P, S, E) 
Every dog has day (D D', H). 

#### <a id="#3A4b"></a>Predicate Arguments

Predicate arguments 
A valid predicate argument: 
A geese are birds. 
A birds have wings. 
A geese have wings. 
(Vx)(Gx Bx) 
Another valid argument (different form): 
All men are mortal. 
Socrates is a man. 
Socrates is mortal. 

### <a id="#3A5"></a>Probabilistic Logic

Probabilistic logic 
We need to assess non-valid arguments 
too 
E.g., weather forecasts 
Apply domain-specific knowledge 
Probabilities can represent such 
knowledge 
• E.g., the probability of rain is 40% 
Extend propositional logic for this purpose 

#### <a id="#3A5a"></a>Probabilistic Symbolization

Probability symbolization 
Probability of proposition p: pr(p) — 
10... Il 
pr(p) O if p is certainly false and 
2 pr(p) 1 if pis certainly true. 
Examples: 
p — "It Will snow in January.- pr(p) .99 
p: "It Will snow in April." pr(p) .65 
p — "It will snow in August." pr(p) .02 
Probability rules 
Rules for probabi ities of complex sentences: 
1 . 1 — pr(p) 
2. pr(p v q) if p q mutually exclusive 
3. • pr(q), if p and 
Examples: 
snow in January.) I — in I - 
.gg- .01 
or 2 on adie roll") — prtl on roll") prr2 on a 
die roll") - 1/6 1,'3 
in January and in January ) 
in .99. .65: 6435 
is an artsve given that she's female.) ?? 

#### <a id="#3A5b"></a>Probabilistic Arguments

Probability arguments 
An argument is convinc'ng if 
. pr(clr) preen 
r — reason, c — conclusion 
Example: 
Verv often. it has snowed in January. 
Probably, it WI I snow next January. 
Calcu ations: 
pr(NlJ) - pr(N & - (.9. - g 
pr(-NlJJ - pr(-N & — • 
The argument is a strong one, probabilistically 
Probability arguments (cont.) 
A weak argument? 
Not a bear in sight. 
The Bear Patrol works. 
Calculations: 
w 
• pr(Wl-B) pr(W & (.5 • .99)/.99 .5 
• pr(-Wl-B) prew & (.5 • .99)/.99 .5 
The argument is weak 
• Assuming pr(W) pr6W) 

## <a id="#3B"></a>Evaluation of Logic

Evaluation of logic 

### <a id="#3B1"></a>Overview

Overview 
Formal logic provides for the symbolization 
and evaluat'on of arguments 
Does logic capture laws Of thought? 
• Aristotle and Boole agreed, Frege d'd not 
Why did the pioneers of CogSci look to 
formal logic? 
• Powerful and rigourous 
• Amenable to computational mode ing 
• Logical thinking 's a hallmark of intelligence 

### <a id="#3B2"></a>Representational Power

Representational power 
Propositional logic captures some val'd 
arguments, e.g., (modus ponens) 
If it rains, then the Sidewalk gets Wet. 
s rain. 
The is Wet. 
Predicate logic captures more valid arguments, 
e.g., 
All men are 
is a man. 
is a mortal, 
Sentences 
To symbolize arguments, formal logic 
focuses on statements 
There are other kinds of sentences, e.g., 
• Questions: "How do I get to the Bookstore 
from here?" 
• Orders: "Set your phasers to k'll!" 
• Requests: "Would you pass the 
salt, please?" 
Texts 
Not all texts are arguments, e.g., 
"I'm sorry but this reading initiative. 'm sorry, Ive 
never been a fan of books. I don't trust them. They're 
all fact, no heart. I mean, they're elitist, tel ing us what 
is Or isn't true, or what did or didn't happen. Who's 
Britannica to tell me the Panama Cana was built in 
1914? f I want to say it was buit in I g41, that's my 
right as an American! I'm with the prescient, let 
history decide what did or did not happen." 
Representational limitations 
Predicate logic is specialized where 
natural languages are generalized 
Doesn't the generalized nature Of 
language reflect the generalized nature of 
thinking, and so mental representations? 
Formal logic has been extended to 
address other k nds of sentences 
The extensions are complex and unwieldy in 
combination 

### <a id="#3B3"></a>Computational Power

Computational power 
Argument construction is a model of 
intelligent thinking 
E.g., when Homer said 
a bear in sight. The Bear patrol must like 
a charm," 
was he thinking. 
is a Bear patrol 
Not a bear in Sight 
The Bear Patrol keeps bears away 
Perhaps thinking is applying rules to symbols, 

#### <a id="#3B3a"></a>Planning

Planning 
Planning: represent goals and steps to ach eve 
them 
E.g., Go from Guelph to LJW: 
3. reach(l University-Ave) 
4. reach(l.Llniversity-Ave) trave (l, University-AVC) 
5. trave reacMI,UW) 
Note the change 'n notation favoured by 
Cognitive Scientists 
A route could be deduced from these rules 
Planning (cont.) 
pro: if a route exists, deduction will determine it 
Cons: Many valid inferences are not helpful: 
If I travel Hwy-7 and Hwy-85, I could deduce. 
• travel(l,Hwy-7) & 
. travel( ,Hwy-7) & & 
The relevance of an inference s unconnected 
with its validity 
Planning (cont.2) 
Deduction is monotonic 
Planning must often be norrmonotonic 
E.g., a route s blocked 
monotonic 
non-monotonic 

#### <a id="#3B3b"></a>Decision

Decision 
Decision: choosing among plans 
Deduction only determines if plans exist 
• Preferences need to be added, e.g., 
travel(l,Hwy-7) —9 & prefer- 
Assumptions of this approach: 
I can completely order my preferences, and 
2. I can know all my preferences before I make 
my plans. 
Decision (cont.) 
Perhaps probabil'ties could address these 
assumptions 
• E.g., decide among English, German, Philosophy 
courses 
is is English") 
This solut'on is computationally explosive 
• pr(AlB) must be known for every A and B 
. For n predicates, there 2M conditional 
probabilities 

#### <a id="#3B3c"></a>Explanation

Explanation 
Why doesn't my favorite Website load? 
Your browser has a bug; 
Your connection s not working properly; 
Your server at your service provider is not 
working; 
The Website server is not working; 
The URL is incorrect. 
Explanation2 
Some deductions are explanations (Hempel) 
—respond(Website) —9 incorrect(URL) 
yespprV(Website) 
incorrect(URL) 
Problems: 
Multiple explanations? 
Some deductions are not explanations, e.g., the 
height of a flagpole 
How do you explain the height of a flagpole? 
Explanation3 
Some explanations are abductions (Peirce) 
down(Website-server) —9 —readable(Website) 
-readableIW ebsite) 
down (Website-sewer) 
Problems: 
. Such inductions are risky 
. Use conditional probability to determine the best 
explanation, e.g., prCM/ebsite server is 
Website is not readable.) 0.4 

#### <a id="#3B3d"></a>Learning

Learning 
Abduction is a form Of learning 
Inductive generalization also, e.g., 
Philosophy(PhiI-128) 8 interesting(PhiI- 128) 
Philosophy(Phil-256j & interesting(Phil-256) 
interesting(x)) 
Problem: risk jump ng to conc usions 
DO you reason in this way? When? 

#### <a id="#3B3e"></a>Psychological Plausibility

Psychological plausibility 
Subjects agree that modus ponens is 
deductive, but not affirming the 
consequent: 
If the Bear Patrol works, then no bears are in sight 
No bears are 'n sight 
Therefore, the Bear Patro works 
Do people think deductively? 
Plausibility2 
Wason card task: 
given four cards from a deck with numbers on 
one sue & letters on the other: (Al (Bl (2) (31. 
Flip which cards to test the rule: If a card has 
an A on one side, then it has an even number 
on the Other side 
Most subjects select IA) and 12); many 
omit 13) 
Plausibility3 
Explanations: 
• People are not logical, do not apply modus tollens: 
. People employ schemata 
• People employ mental models: represent (Al and 
even-number; assume only represented items are 
Plausibility4 
People do not seem to think in accord with the 
axioms of probability, e.g., 
. pr(a) pr(b) pr(b) 
Suppose Frank likes to read French literature, 
attend foreign films, and discuss world politics 
People often judge that 
pr("college-educated") pr("carpenter") pr("carpenter") 
Instead of probability, people employ stereotypes 

#### <a id="#3B3f"></a>Summary

----------



# <a id="#4"></a>Lecture 4. Rules


## <a id="#4A"></a>Rules


### <a id="#4A1"></a>Overview


### <a id="#4A2"></a>History of Rules


### <a id="#4A3"></a>Rules-Based Systems


### <a id="#4A4"></a>Search


#### <a id="#4A4a"></a>Knowledge Space


#### <a id="#4A4b"></a>Search Strategies


#### <a id="#4A4c"></a>Heuristics


#### <a id="#4A4d"></a>Which Strategy to Use


## <a id="#4B"></a>Evaluation of Rules


### <a id="#4B1"></a>Overview


### <a id="#4B2"></a>Representational Power


### <a id="#4B3"></a>Computational Power


#### <a id="#4B3a"></a>Explanation


#### <a id="#4B3b"></a>Learning


#### <a id="#4B3c"></a>Language


### <a id="#4B4"></a>Computational Limitations


### <a id="#4B5"></a>Psychological Plausibility


### <a id="#4B6"></a>Philosophical Issues


----------

# <a id="#5"></a>Lecture 5. Concepts


## <a id="#5A"></a>Concepts


### <a id="#5A1"></a>Overview


### <a id="#5A2"></a>History of Concepts


### <a id="#5A3"></a>Theories of Concepts


#### <a id="#5A3a"></a>Definitions


#### <a id="#5A3b"></a>Prototypes


#### <a id="#5A3c"></a>Exemplars


#### <a id="#5A3d"></a>Causal


### <a id="#5A4"></a>Tomato - Fruit or Vegetable?


## <a id="#5B"></a>Evaluation of Concepts


### <a id="#5B1"></a>Overview


### <a id="#5B2"></a>Representational Power


### <a id="#5B3"></a>Computational Power


#### <a id="#5B3a"></a>Inheritance


#### <a id="#5B3b"></a>Matching


### <a id="#5B4"></a>Psychological Plausibility


#### <a id="#5B4a"></a>Planning


#### <a id="#5B4b"></a>Explanation


#### <a id="#5B4c"></a>Learning


----------

# <a id="#6"></a>Lecture 6. Analogy


## <a id="#6A"></a>Analogy


### <a id="#6A1"></a>Overview


### <a id="#6A2"></a>Analogy as Induction Generalization


### <a id="#6A3"></a>Analogy as Extrapolation


### <a id="#6A4"></a>The Multiconstraint Theory


#### <a id="#6A4a"></a>Representation


#### <a id="#6A4b"></a>Constraints on Coherence


## <a id="#6B"></a>Evaluation of Analogy


### <a id="#6B1"></a>Overview


### <a id="#6B2"></a>Representational Power


#### <a id="#6B2a"></a>Verbal


#### <a id="#6B2b"></a>Visual


#### <a id="#6B2c"></a>Emotional


### <a id="#6B3"></a>Computational Power


#### <a id="#6B3a"></a>Analogy Construction


#### <a id="#6B3b"></a>Explanation


#### <a id="#6B3c"></a>Learning


#### <a id="#6B3d"></a>Metaphor


### <a id="#6B5"></a>Limits of Analogical Reasoning


----------

# <a id="#7"></a>Lecture 7. Images


## <a id="#7A"></a>Images


### <a id="#7A1"></a>Overview


### <a id="#7A2"></a>The Imagery Debate


### <a id="#7A3"></a>Quasi-Pictorialism


### <a id="#7A4"></a>Experimental Evidence for Quasi-Pictorialism


#### <a id="#7A4a"></a>Mental Rotation


#### <a id="#7A4b"></a>Scanning


#### <a id="#7A4c"></a>Zooming and Inspection


#### <a id="#7A4d"></a>Demand Characteristics?


### <a id="#7A5"></a>Neurological Evidence for Quasi-Pictorialism


#### <a id="#7A5a"></a>In Search of the Visual Buffer


#### <a id="#7A5b"></a>Interference


## <a id="#7B"></a>Evaluation of Images


### <a id="#7B1"></a>Overview


### <a id="#7B2"></a>Descriptionism


#### <a id="#7B2a"></a>Infinite Regress


#### <a id="#7B2b"></a>Hedging


#### <a id="#7B2c"></a>Absent Features


#### <a id="#7B2d"></a>Imagery in Interpreted


#### <a id="#7B2e"></a>Computational Equivalence


### <a id="#7B3"></a>Representational Power


#### <a id="#7B3a"></a>Deep


#### <a id="#7B3b"></a>Spatial


#### <a id="#7B3c"></a>Visual


#### <a id="#7B3d"></a>Limitations


### <a id="#7B4"></a>Computational Power


#### <a id="#7B4a"></a>Scientific Discovery


#### <a id="#7B4b"></a>Technical Innovation


#### <a id="#7B4c"></a>Analogy


----------
